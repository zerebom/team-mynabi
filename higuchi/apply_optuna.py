 #!/usr/bin/env python
# coding: utf-8

# In[1]:

import datetime
import optuna
from functools import partial
import numpy as np
import pandas as pd
import scipy as sp
from scipy import stats
from scipy.stats import norm, skew
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()
import matplotlib
font = {'family': 'Yu Mincho'}
matplotlib.rc('font', **font)

pd.set_option('max_columns',1000)
pd.set_option('max_rows',1000)

import warnings
warnings.filterwarnings('ignore') 

import re
import geocoder
from geopy.distance import great_circle, vincenty
from tqdm import tqdm
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
import os
import gc
import lightgbm as lgb
from sklearn.model_selection import KFold, train_test_split
from time import time
import datetime
from script import RegressionPredictor
import japanize_matplotlib
# print(os.listdir("././input"))
# print(os.listdir("././submit"))
SEED=1234
n_splits=10


# In[2]:


train=pd.read_csv('./input/prep_train1030.csv')
test=pd.read_csv('./input/prep_train1030.csv')
y_train = train['賃料']


# In[3]:


drop_col = ['id','賃料']
## 必要な特徴量に絞る
y_train = train['賃料']
y_train_log = np.log1p(y_train)
X_train = train.drop(drop_col,axis=1)
X_test = test.drop(drop_col,axis=1)
features = ['面積','築年数','sta_min','center_dis','loc_lat','loc_lon','総階数','所在階','2017平均単価_mean','山手線','千代田線','日比谷線','丸ノ内線']
X_train = X_train[features]
X_test = X_test[features]


# In[4]:


def get_default_parameter_suggestions(trial):
    """
    Get parameter sample for Boosting (like XGBoost, LightGBM)

    Args:
        trial(trial.Trial):

    Returns:
        dict: parameter sample generated by trial object
    """
    return {
        'num_iterations': 15000,
        'boosting_type': 'gbdt',
        'objective': 'regression',
        'metric': 'mae',
        'random_state': 0,
        'verbose': -1,
        # L2 正則化
        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 1e3),
        # L1 正則化
        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 1e3),
        # 弱学習木ごとに使う特徴量の割合
        # 0.5 だと全体のうち半分の特徴量を最初に選んで, その範囲内で木を成長させる
        'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1.0, .1),
        # 学習データ全体のうち使用する割合
        # colsample とは反対に row 方向にサンプルする
        'subsample': trial.suggest_discrete_uniform('subsample', .5, 1., .1),
        # 木の最大の深さ
        # たとえば 5 の時各弱学習木の各データに対するルールは、最大でも5に制限される.
        'max_depth': trial.suggest_int('max_depth', 3, 8),
        # 末端ノードに含まれる最小のサンプル数
        # これを下回るような分割は作れなくなるため, 大きく設定するとより全体の傾向でしか分割ができなくなる
        # [NOTE]: 数であるのでデータセットの大きさ依存であることに注意
        'min_child_weight': trial.suggest_int('min_child_weight', 5, 40)
    }

    


# In[7]:


def objective(X_train,y_train,X_test,trial):
    params=get_default_parameter_suggestions(trial)
    kf = KFold(n_splits=3, random_state=SEED)

    rmses = list()

    oof = pd.DataFrame({'id':list(train.id.values),'y_train':list(y_train.values)})

    for fold, (trn_idx, val_idx) in enumerate(kf.split(X_train, y_train_log)):
        start_time = time()
        print('Training on fold {}'.format(fold + 1))

        tr_x, tr_y = X_train.iloc[trn_idx], y_train_log.iloc[trn_idx]
        vl_x, vl_y = X_train.iloc[val_idx], y_train_log.iloc[val_idx]

        tr_data = lgb.Dataset(tr_x, label=tr_y)
        vl_data = lgb.Dataset(vl_x, label=vl_y)
        clf = lgb.train(params, tr_data, 5000, valid_sets = [tr_data, vl_data], verbose_eval=5000)
        oof.loc[val_idx,'oof'] = np.expm1(clf.predict(vl_x, num_iteration=clf.best_iteration))

        ## アンサンブル

        rmses.append(clf.best_score['valid_1']['l1'])

        del tr_x, tr_y, vl_x, vl_y, tr_data, vl_data
        gc.collect()
    return np.sqrt(mean_squared_error(oof['oof'], oof['y_train']))


# In[ ]:


f = partial(objective,X_train,y_train,X_test)
study = optuna.create_study()
study.optimize(f, n_trials=100)

with open(f'./best_params_by_oputuna{datetime.datetime.today()}.txt') as f:
    f.write(str(study.best_params()))

df=study.trials_dataframe()
df.to_csv(f'../optuna_study_log_{datetime.datetime.today()}.csv')

# In[ ]:





# In[ ]:




