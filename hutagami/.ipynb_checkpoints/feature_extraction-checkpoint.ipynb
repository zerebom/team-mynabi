{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import MeCab\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ディレクトリ構造\n",
    "root/  \n",
    "　├ code/ here  \n",
    "　├ data/   \n",
    "　├ rawdata/  \n",
    "　└ adddata/   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../rawdata/train.csv', index_col='id')\n",
    "test_data = pd.read_csv('../rawdata/test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方向性（前処理）\n",
    "- 所在地は丁目の前までにする（たぶんMeCabとか使えばできる）\n",
    "- アクセスも分解して、'最寄り駅名'、'最寄り徒歩'、（この２つは3番目までくらいはあってもいいかも）、'複数徒歩圏内'とかに分ける\n",
    "- 間取りはOne-hotベクトル化\n",
    "- 築年数は月数に換算する\n",
    "- 方角はOne-hotベクトル化（南東とかどうするかは検討）\n",
    "- 面積はそのままでよい（数値化）\n",
    "- 所在階は分解して'所在階'と'何階建て'にする\n",
    "- バス・トイレも要素を分解してOne-hotベクトル化する\n",
    "- キッチンも同様\n",
    "- 放送・通信も同様\n",
    "- 室内設備も同様\n",
    "- 駐車場は値段が書いてある場合と書いてない場合でどうするか検討\n",
    "- 周辺環境は隅付き括弧の内容をまず抜き出してOne-hotベクトル化\n",
    "- 構造もOne-hotベクトル化\n",
    "- 契約期間は、'契約期間'、'定期借家 or not'に分ける  \n",
    "データ加工について\n",
    "- 最寄り駅の平均賃料($1m^2$あたり)を算出\n",
    "- 間取りは'部屋数', 'K', 'DK', 'LDK'に変換したほうが良いかも\n",
    "\n",
    "他のデータ利用について\n",
    "- geocodingを用いて緯度経度orX,Yに変換  \n",
    "  近傍を探索し、近傍の部件の平均賃料と標準偏差($1m^2$あたり)を算出\n",
    "- 住みたい駅ランキングとか引っ張ってきてもいいかも(結局賃料に加味されている気がしないことも無いが)\n",
    "- レポート出すならVisualize頑張る\n",
    "- お得物件とか探してもいいかも"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 半角全角が入り混じってるのでまず全て半角に変換\n",
    "def zen2han(text):\n",
    "    if str(text) != str(np.nan):\n",
    "        return text.translate(str.maketrans({chr(0xFF01 + i): chr(0x21 + i) for i in range(94)}))\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# 駅名をきれいにする\n",
    "def get_station_list(station_list):\n",
    "    station_list = [re.sub('\\(.+?\\)', '', text.replace('「','').replace('」','').replace('『','').replace('』','')) for text in station_list]\n",
    "    station_list = [re.sub('（.+?）', '', text.replace('・','')) for text in station_list]\n",
    "    return np.array(station_list)\n",
    "\n",
    "# 路線名をきれいにする\n",
    "def get_route_list(route_list):\n",
    "    route_list = [text.replace('JR','')\n",
    "                      .replace('ＪＲ','')\n",
    "                      .replace('東京メトロ','')\n",
    "                      .replace('小田急電鉄','')\n",
    "                      .replace('小田急','')\n",
    "                      .replace('都営','')\n",
    "                      .replace('メトロ','') for text in route_list]\n",
    "    return np.array(list(route_list))\n",
    "\n",
    "\n",
    "# 所要時間を計算する\n",
    "def get_times(times):\n",
    "    new_times = []\n",
    "    for time in times:\n",
    "        if 'バス' in time:\n",
    "            time = time.replace('・','').replace('バス','').replace('徒歩','').replace('分','').replace('(','').replace(')','').split('下車')\n",
    "            time = sum([int(re.sub(\"\\\\D\", \"\", i)) if i != '' else int(0) for i in time])\n",
    "        elif '車' in time:\n",
    "            time = int(re.sub(\"\\\\D\", \"\", re.sub('車.{0,5}km','',time)))\n",
    "        else:\n",
    "            #time = int(time.replace('まで','').replace('徒歩','').replace('・','').replace('分','').replace('(','').replace(')',''))\n",
    "            time = re.sub(\"\\D\", \"\", time)\n",
    "            if time != '':\n",
    "                time = int(time)\n",
    "            else:\n",
    "                time = 60\n",
    "        new_times.append(time)\n",
    "    return new_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 色々含まれているカラムを分割する\n",
    "def split_items(item_pd):\n",
    "    # 含まれている内容を分割\n",
    "    item_dict = item_pd.str.replace('\\t/', '/').str.replace('/', '').str.split('\\t').to_dict()\n",
    "    \n",
    "    # 内容のユニーク値を出す\n",
    "    item_list = []\n",
    "    for item in list(item_dict.values()):\n",
    "        if str(item) != str(np.nan):\n",
    "            item_list.extend(item)\n",
    "            item_list = list(np.unique(item_list))\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    # One-hotベクトル化\n",
    "    new_item_pd = pd.DataFrame(index=item_pd.index, columns=item_list)\n",
    "    for item in item_list:\n",
    "        new_item_pd[item] = item_pd.str.contains(item, na=False)\n",
    "    \n",
    "    return new_item_pd\n",
    "\n",
    "# 駐車場\n",
    "def split_parking(parking_list):\n",
    "    park = ['駐車場', '駐輪場', 'バイク置き場']\n",
    "    park_type = True\n",
    "    last_type = None\n",
    "    car = np.nan\n",
    "    bicycle = np.nan\n",
    "    bike = np.nan\n",
    "    car_place = np.nan\n",
    "    car_price = np.nan\n",
    "    \n",
    "    if str(parking_list) != str(np.nan):\n",
    "        for text in parking_list:\n",
    "            if park_type == True:\n",
    "                if text in park:\n",
    "                    park_type = text\n",
    "                    last_type = text\n",
    "                else:\n",
    "                    if last_type == '駐車場':\n",
    "                        if text[:2] == '距離':\n",
    "                            car_place = text\n",
    "                        elif text[0] != '(' and 'ヶ月' not in text:\n",
    "                            car_price = text\n",
    "                    park_type = True\n",
    "            elif park_type == '駐車場':\n",
    "                if text == '近隣':\n",
    "                    car = '空有'\n",
    "                    park_type = '価格'\n",
    "                else:\n",
    "                    car = text\n",
    "                    park_type = True\n",
    "            elif park_type == '駐輪場':\n",
    "                bicycle = text\n",
    "                park_type = True\n",
    "            elif park_type == 'バイク置き場':\n",
    "                bike = text\n",
    "                park_type = True\n",
    "            elif park_type == '価格':\n",
    "                car_price = text\n",
    "                park_type = '距離'\n",
    "            elif park_type == '距離':\n",
    "                car_place = text\n",
    "                park_type = True\n",
    "            else:\n",
    "                car = np.nan\n",
    "                bicycle = np.nan\n",
    "                bike = np.nan\n",
    "                car_place = np.nan\n",
    "                car_price = np.nan\n",
    "    \n",
    "    return car, bicycle, bike, car_place, car_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所在地の処理\n",
    "def get_location(data):\n",
    "    #re.split('(.+?[都道府県])(.+?[市区町村])(.+?\\d[丁目])', text)\n",
    "    # 形態素解析を用いて区名等を判別\n",
    "    new_pd = pd.DataFrame(index=data['所在地'].index, columns=['都道府県', '市区町村', '町丁字'])\n",
    "    t = MeCab.Tagger('-Owakati')\n",
    "    for i, text in tqdm(zip(data['所在地'].index, data['所在地'])):\n",
    "        location = t.parse(text).split()[:5]\n",
    "        if len(location) == 5:\n",
    "            new_pd.loc[i] = ([location[0]+location[1], location[2]+location[3], location[4]])\n",
    "        elif len(location) == 4:\n",
    "            new_pd.loc[i] = ([location[0]+location[1], location[2]+location[3], np.nan])\n",
    "        elif len(location) == 2:\n",
    "            new_pd.loc[i] = ([location[0]+location[1], 'その他', 'その他'])\n",
    "        else:\n",
    "            new_pd.loc[i] = (['その他', 'その他', 'その他'])\n",
    "    # 東京都のみなので都道府県名は気にしない\n",
    "    #return pd.get_dummies(new_pd[['市区町村', '町丁字']], columns=['市区町村', '町丁字'])\n",
    "    return new_pd[['市区町村', '町丁字']]\n",
    "\n",
    "\n",
    "# アクセスの処理\n",
    "def get_access(data):\n",
    "    # ひたすら前処理\n",
    "    # ミスと思われるものを修正\n",
    "    access = data['アクセス'].str.split('\\t\\t').to_dict()\n",
    "    data['アクセス'] = (data['アクセス'].str.replace('\\t\\t都営大江戸線\\u3000西新宿五丁目駅駅', '').str.replace('.','')\n",
    "                                    .str.replace('－','-').str.replace('都営大江戸線『六本木』', '都営大江戸線六本木駅')\n",
    "                                    .str.replace('\\t\\t京王井の頭線\\t永福町駅\\t徒歩22分\\t\\t京王線井の頭線\\u3000永福町駅','\\t\\t京王井の頭線\\t永福町駅\\t徒歩22分'))\n",
    "    route_list = []\n",
    "    station_list = []\n",
    "    for i in tqdm(access.keys()):\n",
    "        text = data['アクセス'].loc[i].replace('\\t','').replace('\\u3000','').replace(':','').replace('：','').replace('/','')\n",
    "        text = text.replace('・東京メトロ銀座線『上野広小路』', '東京メトロ銀座線上野広小路駅')\n",
    "        text = text.replace('・山手線『上野』', '山手線上野駅')\n",
    "        text = (text.replace('日暮里・舎人ライナー', '日暮里・舎人ライナー* ')\n",
    "                    .replace('ゆりかもめ', 'ゆりかもめ* ')\n",
    "                    .replace('エクスプレス', 'エクスプレス* ')\n",
    "                    .replace('ツリーライン', 'ツリーライン* ')\n",
    "                    .replace('湘南新宿ライン', '湘南新宿ライン* ')\n",
    "                    .replace('ディズニーリゾートライン', 'ディズニーリゾートライン* ')\n",
    "                    .replace('線・', '・')\n",
    "                    .replace('線)', ')')\n",
    "                    .replace('線）', '）')\n",
    "                    .replace('線', '線* ')\n",
    "                    .replace('駅', '駅* ')\n",
    "                    .replace('駅* 前駅* ', '駅前駅* '))\n",
    "        text = re.sub('バス\\((?P<time>\\d+)分\\).+?下車徒歩','バス(\\g<time>分)下車徒歩',text)\n",
    "        text = re.sub('バス(?P<time>\\d+)分.+?下車徒歩','バス(\\g<time>分)下車徒歩',text)\n",
    "        text = re.sub('バス\\((?P<time>\\d+)分\\).+?下車(?P<some>[^(徒歩)])','バス(\\g<time>分)下車* \\g<some>',text)\n",
    "        text = re.sub('バス(?P<time>\\d+)分.+?下車(?P<some>[^(徒歩)])','バス(\\g<time>分)下車* \\g<some>',text)\n",
    "        text = re.sub('km\\((?P<time>\\d+)分\\)','km(\\g<time>分)* ',text)\n",
    "        text = re.sub('\\((?P<line1>.+?)線* -(?P<line2>.+?)\\)','(\\g<line1>線-\\g<line2>線)',text)\n",
    "        a = np.array(re.sub('徒歩(?P<time>\\d+)分','徒歩\\g<time>分* ',text).split('* '))\n",
    "        a = np.delete(a, -1)\n",
    "        access[i] = np.array([a[3*j:3*j+3] for j in range(int(len(a)/3))])\n",
    "        route_list.extend(list(access[i][:, 0]))\n",
    "        route_list = list(np.unique(route_list))\n",
    "        #station_list.extend(list(access[i][:, 1]))\n",
    "        #station_list = list(np.unique(station_list))\n",
    "\n",
    "    # 駅名と路線名の一覧を取得\n",
    "    #station_list = np.unique(get_station_list(station_list))\n",
    "    route_list = np.unique(get_route_list(route_list))\n",
    "\n",
    "    # 利用可能駅数を取得\n",
    "    available_station = pd.DataFrame([len(access[i]) for i in access.keys()], index=data.index, columns=['利用可能駅数'])\n",
    "\n",
    "    # 利用可能路線数を取得\n",
    "    available_routes = pd.DataFrame([len(np.unique(get_route_list(access[i][:, 0]))) for i in access.keys()], index=data.index, columns=['利用可能路線数'])\n",
    "\n",
    "    # バスが必要か\n",
    "    need_bus = pd.DataFrame(data['アクセス'].str.contains('バス').values, index=data.index, columns=['バス利用'])\n",
    "\n",
    "    # 車が必要か\n",
    "    need_car = pd.DataFrame(((data['アクセス'].str.contains('車')) & (data['アクセス'].str.contains('km'))).values, index=data.index, columns=['車利用']) \n",
    "\n",
    "    routes = [get_route_list(access[i][:, 0]) for i in access.keys()]\n",
    "    stations = [get_station_list(access[i][:, 1]) for i in access.keys()]\n",
    "    times = [get_times(access[i][:, 2]) for i in access.keys()]\n",
    "\n",
    "    # 所要時間を記したデータフレームの作成\n",
    "    \"\"\"\n",
    "    station_pd = pd.DataFrame(index=data.index, columns=station_list)\n",
    "    route_pd = pd.DataFrame(index=data.index, columns=route_list)\n",
    "\n",
    "    i = 0\n",
    "    for key in tqdm(access.keys()):\n",
    "        station_pd.loc[key, stations[i]] = times[i]\n",
    "        route_pd.loc[key, routes[i]] = times[i]\n",
    "        i += 1\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    dict_index = 0\n",
    "    #station_pd = {}\n",
    "    route_pd = {}\n",
    "    while True:\n",
    "        num = 0\n",
    "        #station_pd[dict_index] = pd.DataFrame(columns=station_list)\n",
    "        route_pd[dict_index] = pd.DataFrame(columns=route_list)\n",
    "        while num < 1000: \n",
    "            i = list(access.keys())[count]\n",
    "            #append_pd = pd.DataFrame(times[count], index=stations[count], columns=[i]).groupby(level=0).last().T\n",
    "            #station_pd[dict_index] = station_pd[dict_index].append(append_pd, sort=True)\n",
    "            append_pd = pd.DataFrame(times[count], index=routes[count], columns=[i]).groupby(level=0).last().T\n",
    "            route_pd[dict_index] = route_pd[dict_index].append(append_pd, sort=True)\n",
    "            count += 1\n",
    "            num += 1\n",
    "            #print(count, end=',')\n",
    "            if count == len(access.keys()):\n",
    "                break\n",
    "        dict_index += 1\n",
    "        if count == len(access.keys()):\n",
    "            break\n",
    "    \"\"\"\n",
    "\n",
    "    #station_pd = pd.concat([i for i in station_pd.values()], axis=0)\n",
    "    #route_pd = pd.concat([i for i in route_pd.values()], axis=0)\n",
    "    #route_pd = route_pd.fillna(60)\n",
    "\n",
    "    new_pd = pd.concat([available_station, available_routes, need_bus, need_car, \n",
    "                        #station_pd, \n",
    "                        #route_pd\n",
    "                       ], axis=1)\n",
    "    new_pd['最小所要時間'] = [np.min(i) for i in times]\n",
    "    new_pd['最大所要時間'] = [np.max(i) for i in times]\n",
    "    new_pd['平均所要時間'] = [np.mean(i) for i in times]\n",
    "    return new_pd\n",
    "\n",
    "\n",
    "# 間取りの処理\n",
    "def get_layout(data):\n",
    "    # 納戸ありは少ないので最初から分割\n",
    "    stock = pd.DataFrame(data['間取り'].str.contains('納戸').values, index=data['間取り'].index, columns=['納戸有無'] )\n",
    "    data['間取り'] = data['間取り'].str.replace('\\+S\\(納戸\\)', '')\n",
    "    # あとはOne-hotベクトル化\n",
    "    \n",
    "    #return pd.concat([pd.get_dummies(data['間取り'], columns=['間取り']), stock], axis=1)\n",
    "    data['間取り'] = data['間取り'].str.replace('LK', 'LDK')\n",
    "\n",
    "    data['LDK'] = data['間取り'].str.contains('LDK')\n",
    "    data['間取り'] = data['間取り'].str.replace('LDK', '')\n",
    "\n",
    "    data['DK'] = data['間取り'].str.contains('DK')\n",
    "    data['間取り'] = data['間取り'].str.replace('DK', '')\n",
    "\n",
    "    data['K'] = data['間取り'].str.contains('K')\n",
    "    data['間取り'] = data['間取り'].str.replace('K', '')\n",
    "\n",
    "    data['R'] = data['間取り'].str.contains('R')\n",
    "    data['間取り'] = data['間取り'].str.replace('R', '')\n",
    "\n",
    "    data['部屋数'] = data['間取り'].astype('int')\n",
    "    \n",
    "    return pd.concat([data[['部屋数', 'LDK', 'DK', 'K', 'R']], stock], axis=1)\n",
    "\n",
    "\n",
    "# 築年数の処理\n",
    "def get_age(data):\n",
    "    age_month = [int(i[0])*12 + int(i[1]) if len(i)==2 else int(i[0])*12 if i[0] != '新築' else 0 for i in data['築年数'].str.replace('ヶ月','').str.split('年')]\n",
    "    return pd.DataFrame(age_month, index=data.index, columns=['築月数'])\n",
    "\n",
    "\n",
    "# 方角の処理\n",
    "def get_direction(data):\n",
    "    # One-hotベクトル化\n",
    "    return pd.get_dummies(data['方角'], columns=['方角'])\n",
    "\n",
    "\n",
    "# 面積の処理\n",
    "def get_area(data):\n",
    "    # 数値化\n",
    "    return pd.DataFrame(data['面積'].str.replace('m2','').astype(float).values, index=data.index, columns=['面積'])\n",
    "\n",
    "\n",
    "# 所在階の処理\n",
    "def get_floor(data):\n",
    "    # 所在階と合計階数と地下階数に分ける\n",
    "    floor = [int(re.findall('(\\d+階[^建][^)])', i)[0][:-3]) if len(re.findall('(\\d+階[^建][^)])', i)) != 0 else np.nan  for i in data['所在階'].astype(str)]\n",
    "    total_floor = [int(re.findall('(\\d+階建)', i)[0][:-2]) if len(re.findall('(\\d+階建)', i)) != 0 else np.nan  for i in data['所在階'].astype(str)]\n",
    "    under_floor = [int(re.findall('(地下\\d+階)', i)[0][2:-1]) if len(re.findall('(地下\\d+階)', i)) != 0 else 0  for i in data['所在階'].astype(str)]\n",
    "    floor_pd = pd.DataFrame({'所在階': floor, '合計階数': total_floor, '地下階数': under_floor}, index=data.index)\n",
    "    floor_pd = floor_pd.fillna(floor_pd.median())\n",
    "    return floor_pd\n",
    "\n",
    "\n",
    "# 駐車場の処理\n",
    "def get_parking(data):\n",
    "    parking = pd.DataFrame(index=data.index, columns=['駐車場', '駐輪場', 'バイク置き場', '駐車場(距離)', '駐車場(価格)'])\n",
    "    for i, parking_list in zip(data.index, data['駐車場'].str.split('\\t')):\n",
    "        parking.loc[i] = split_parking(parking_list)\n",
    "        \n",
    "    parking.loc[parking['駐車場'][(parking['駐車場'].str.contains('有', na=False)) | (parking['駐車場'].str.contains('近隣', na=False))].index, '駐車場'] = True\n",
    "    parking.loc[parking['駐車場'][parking['駐車場'].str.contains('無', na=False)].index, '駐車場'] = False\n",
    "    parking.loc[parking['駐輪場'][(parking['駐輪場'].str.contains('有', na=False)) | (parking['駐輪場'].str.contains('近隣', na=False))].index, '駐輪場'] = True\n",
    "    parking.loc[parking['駐輪場'][parking['駐輪場'].str.contains('無', na=False)].index, '駐輪場'] = False\n",
    "    parking.loc[parking['バイク置き場'][(parking['バイク置き場'].str.contains('有', na=False)) | (parking['バイク置き場'].str.contains('近隣', na=False))].index, 'バイク置き場'] = True\n",
    "    parking.loc[parking['バイク置き場'][parking['バイク置き場'].str.contains('無', na=False)].index, 'バイク置き場'] = False\n",
    "    \n",
    "    parking = parking.drop(['駐車場(距離)', '駐車場(価格)'], axis=1)\n",
    "    parking = parking.fillna(False)\n",
    "    return parking\n",
    "\n",
    "\n",
    "# 周辺環境の処理\n",
    "def get_around(data):\n",
    "    new_dict = {}\n",
    "    facility_list = []\n",
    "    for i, item in zip(data.index, data['周辺環境']):\n",
    "        if str(item) != str(np.nan):\n",
    "            new_dict[i] = np.array([text.split() for text in item.split('\\t')])\n",
    "            facility_list.extend(new_dict[i][:,0])\n",
    "            facility_list = list(np.unique(facility_list))\n",
    "        else:\n",
    "            new_dict[i] = np.nan\n",
    "\n",
    "    new_pd = pd.DataFrame(index=data.index, columns=facility_list)\n",
    "    for i in tqdm(new_dict.keys()):\n",
    "        if str(new_dict[i]) != str(np.nan):\n",
    "            new_pd.loc[i, new_dict[i][:,0]] = new_dict[i][:,1]\n",
    "    new_pd.columns = new_pd.columns.str.replace('【','').str.replace('】','')\n",
    "    for column in new_pd.columns:\n",
    "        new_pd[column] = new_pd[column].str.replace('m','').astype(float)\n",
    "    new_pd = new_pd.fillna(0)\n",
    "    return new_pd\n",
    "\n",
    "\n",
    "# 建物構造の処理\n",
    "def get_structure(data):\n",
    "    return pd.get_dummies(data['建物構造'], columns=['建物構造'])\n",
    "\n",
    "\n",
    "# 契約期間の処理\n",
    "def get_contract(data):\n",
    "    regular = data['契約期間'].str.contains('\\t※この物件は\\t定期借家\\tです。')\n",
    "    data['契約期間'] = data['契約期間'].str.replace('\\t※この物件は\\t定期借家\\tです。', '')\n",
    "\n",
    "    month = []\n",
    "    for text in data['契約期間']:\n",
    "        if str(text) != str(np.nan):\n",
    "            if 'まで' in text:\n",
    "                contract = int((datetime.datetime.strptime(text, '%Y年%m月まで') + datetime.timedelta(days=30) - datetime.datetime.strptime('2019年1月', '%Y年%m月')).days/31)\n",
    "            elif '年間' in text:\n",
    "                contract = int(text[:-2])*12\n",
    "            elif 'ヶ月間' in text:\n",
    "                if '年' in text:\n",
    "                    contract = int(text.replace('ヶ月間','').split('年')[0])*12 + int(text.replace('ヶ月間','').split('年')[1])\n",
    "                else:\n",
    "                    contract = int(text.replace('ヶ月間',''))\n",
    "\n",
    "            month.append(contract)\n",
    "        else:\n",
    "            month.append(np.nan)\n",
    "\n",
    "    new_pd = pd.DataFrame(index=data.index, columns=['契約期間(月)', '定期借家'])\n",
    "    new_pd['契約期間(月)'] = month\n",
    "    new_pd['定期借家'] = regular.values\n",
    "    new_pd = new_pd.fillna(new_pd.median())\n",
    "    return new_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(train):\n",
    "    # 全角を半角に\n",
    "    for column in ['所在地', 'アクセス', '間取り', '築年数', '面積', '所在階', 'バス・トイレ', 'キッチン', '放送・通信', '室内設備', '駐車場', '周辺環境', '建物構造', '契約期間']:\n",
    "        train[column] = [zen2han(text) for text in train[column]]\n",
    "    # 答えデータ\n",
    "    y = train['賃料']\n",
    "    #train_data = pd.DataFrame(index=train.index)\n",
    "\n",
    "    location = get_location(train)  # 所在地\n",
    "    #access = get_access(train)  # アクセス\n",
    "    layout = get_layout(train)  # 間取り\n",
    "    age = get_age(train)  # 築年（月）数\n",
    "    direction = get_direction(train)  # 方角\n",
    "    area = get_area(train)  # 面積\n",
    "    floor = get_floor(train)  # 所在階\n",
    "    bath_toilet = split_items(train['バス・トイレ'])  # バス・トイレ\n",
    "    kitchen = split_items(train['キッチン'])  # キッチン\n",
    "    broadcast = split_items(train['放送・通信'])  # 放送・通信\n",
    "    facility = split_items(train['室内設備'])  # 室内設備　\n",
    "    parking = get_parking(train)  # 駐車場\n",
    "    around = get_around(train)  # 周辺環境\n",
    "    structure = get_structure(train)  # 建物構造\n",
    "    contract = get_contract(train)  # 契約期間\n",
    "    \n",
    "    X = pd.concat([location, #access,\n",
    "                   layout, age, direction, area, floor, bath_toilet, kitchen, broadcast, facility, parking, around, structure, contract], axis=1)\n",
    "    y_per_area = train['賃料'] / X['面積']\n",
    "    \n",
    "    # 前処理後の処理\n",
    "    sample = X.copy()\n",
    "    sample['target_per_面積'] = y_per_area\n",
    "    \n",
    "    city_mean = sample.groupby('市区町村')['target_per_面積'].mean()\n",
    "    city_std = sample.groupby('市区町村')['target_per_面積'].std()\n",
    "\n",
    "    town_mean = sample.groupby('町丁字')['target_per_面積'].mean()\n",
    "    town_std = sample.groupby('町丁字')['target_per_面積'].std()\n",
    "\n",
    "    X['市区町村_mean_per_area'] = sample['市区町村'].replace(dict(zip(city_mean.index, city_mean.values)))\n",
    "    X['市区町村_std_per_area'] = sample['市区町村'].replace(dict(zip(city_std.index, city_std.values)))\n",
    "    X['町丁字_mean_per_area'] = sample['町丁字'].replace(dict(zip(town_mean.index, town_mean.values)))\n",
    "    X['町丁字_std_per_area'] = sample['町丁字'].replace(dict(zip(town_std.index, town_std.values)))\n",
    "    \n",
    "    X['市区町村_mean'] = X['市区町村_mean_per_area'] * X['面積']\n",
    "    X['市区町村_std'] = X['市区町村_std_per_area'] * X['面積']\n",
    "    X['町丁字_mean'] = X['町丁字_mean_per_area'] * X['面積']\n",
    "    X['町丁字_std'] = X['町丁字_std_per_area'] * X['面積']\n",
    "    \n",
    "    X = X.drop(['市区町村', '町丁字'], axis=1)\n",
    "    \n",
    "    # testデータ用に保存\n",
    "    city_mean.to_pickle('../data/city_mean.pkl')\n",
    "    city_std.to_pickle('../data/city_std.pkl')\n",
    "    town_mean.to_pickle('../data/town_mean.pkl')\n",
    "    town_std.to_pickle('../data/town_std.pkl')\n",
    "    \n",
    "    return X, y, y_per_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(test):\n",
    "    # 全角を半角に\n",
    "    for column in ['所在地', 'アクセス', '間取り', '築年数', '面積', '所在階', 'バス・トイレ', 'キッチン', '放送・通信', '室内設備', '駐車場', '周辺環境', '建物構造', '契約期間']:\n",
    "        test[column] = [zen2han(text) for text in test[column]]\n",
    "    \n",
    "    #test_data = pd.DataFrame(index=test.index)\n",
    "\n",
    "    location = get_location(test)  # 所在地\n",
    "    #access = get_access(test)  # アクセス\n",
    "    layout = get_layout(test)  # 間取り\n",
    "    age = get_age(test)  # 築年（月）数\n",
    "    direction = get_direction(test)  # 方角\n",
    "    area = get_area(test)  # 面積\n",
    "    floor = get_floor(test)  # 所在階\n",
    "    bath_toilet = split_items(test['バス・トイレ'])  # バス・トイレ\n",
    "    kitchen = split_items(test['キッチン'])  # キッチン\n",
    "    broadcast = split_items(test['放送・通信'])  # 放送・通信\n",
    "    facility = split_items(test['室内設備'])  # 室内設備　\n",
    "    parking = get_parking(test)  # 駐車場\n",
    "    around = get_around(test)  # 周辺環境\n",
    "    structure = get_structure(test)  # 建物構造\n",
    "    contract = get_contract(test)  # 契約期間\n",
    "    \n",
    "    test_data = pd.concat([location, #access, \n",
    "                           layout, age, direction, area, floor, bath_toilet, kitchen, broadcast, facility, parking, around, structure, contract], axis=1)\n",
    "    \n",
    "    # 前処理後の処理\n",
    "    sample = test_data.copy()\n",
    "    \n",
    "    city_mean = pd.read_pickle('../data/city_mean.pkl')\n",
    "    city_std = pd.read_pickle('../data/city_std.pkl')\n",
    "    town_mean = pd.read_pickle('../data/town_mean.pkl')\n",
    "    town_std = pd.read_pickle('../data/town_std.pkl')\n",
    "    \n",
    "    test_data['市区町村_mean_per_area'] = sample['市区町村'].replace(dict(zip(city_mean.index, city_mean.values)))\n",
    "    test_data['市区町村_std_per_area'] = sample['市区町村'].replace(dict(zip(city_std.index, city_std.values)))\n",
    "    test_data['町丁字_mean_per_area'] = sample['町丁字'].replace(dict(zip(town_mean.index, town_mean.values)))\n",
    "    test_data['町丁字_std_per_area'] = sample['町丁字'].replace(dict(zip(town_std.index, town_std.values)))\n",
    "    \n",
    "    # trainになかった市区町村はnp.nanにして後で補完\n",
    "    test_data.loc[test_data[test_data['市区町村_mean_per_area'].astype(str) > str(99999999)].index, ['市区町村_mean_per_area', '市区町村_std_per_area']] = np.nan\n",
    "    test_data.loc[test_data[test_data['町丁字_mean_per_area'].astype(str) > str(99999999)].index, ['町丁字_mean_per_area', '町丁字_std_per_area']] = np.nan\n",
    "    \n",
    "    test_data['市区町村_mean_per_area'] = test_data['市区町村_mean_per_area'].fillna(test_data['市区町村_mean_per_area'].median())\n",
    "    test_data['市区町村_std_per_area'] = test_data['市区町村_std_per_area'].fillna(test_data['市区町村_std_per_area'].median())\n",
    "    test_data['町丁字_mean_per_area'] = test_data['町丁字_mean_per_area'].fillna(test_data['町丁字_mean_per_area'].median())\n",
    "    test_data['町丁字_std_per_area'] = test_data['町丁字_std_per_area'].fillna(test_data['町丁字_std_per_area'].median())\n",
    "    \n",
    "    test_data['市区町村_mean'] = test_data['市区町村_mean_per_area'] * test_data['面積']\n",
    "    test_data['市区町村_std'] = test_data['市区町村_std_per_area'] * test_data['面積']\n",
    "    test_data['町丁字_mean'] = test_data['町丁字_mean_per_area'] * test_data['面積']\n",
    "    test_data['町丁字_std'] = test_data['町丁字_std_per_area'] * test_data['面積']\n",
    "    \n",
    "    test_data = test_data.drop(['市区町村', '町丁字'], axis=1)\n",
    "    \n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata = train_data.copy()\\nfor column in ['所在地', 'アクセス', '間取り', '築年数', '面積', '所在階', 'バス・トイレ', 'キッチン', '放送・通信', '室内設備', '駐車場', '周辺環境', '建物構造', '契約期間']:\\n        data[column] = [zen2han(text) for text in data[column]]\\n\""
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "data = train_data.copy()\n",
    "for column in ['所在地', 'アクセス', '間取り', '築年数', '面積', '所在階', 'バス・トイレ', 'キッチン', '放送・通信', '室内設備', '駐車場', '周辺環境', '建物構造', '契約期間']:\n",
    "        data[column] = [zen2han(text) for text in data[column]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata = test_data.copy()\\nfor column in ['所在地', 'アクセス', '間取り', '築年数', '面積', '所在階', 'バス・トイレ', 'キッチン', '放送・通信', '室内設備', '駐車場', '周辺環境', '建物構造', '契約期間']:\\n        data[column] = [zen2han(text) for text in data[column]]\\n\""
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "data = test_data.copy()\n",
    "for column in ['所在地', 'アクセス', '間取り', '築年数', '面積', '所在階', 'バス・トイレ', 'キッチン', '放送・通信', '室内設備', '駐車場', '周辺環境', '建物構造', '契約期間']:\n",
    "        data[column] = [zen2han(text) for text in data[column]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31470it [01:55, 272.48it/s]\n",
      "100%|██████████| 31470/31470 [04:51<00:00, 108.02it/s]\n",
      "31262it [02:19, 224.79it/s]\n",
      "100%|██████████| 31262/31262 [04:30<00:00, 115.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 9s, sys: 4.01 s, total: 18min 13s\n",
      "Wall time: 18min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, target, target_per_area = get_train_data(train_data)\n",
    "test = get_test_data(test_data)\n",
    "\n",
    "train_copy = train.copy()\n",
    "target_copy = target.copy()\n",
    "test_copy = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "gam_fe = train.copy()\n",
    "gam_fe.columns = 'gam_' + gam_fe.columns\n",
    "gam_fe.to_csv('../data/gam_train_fe.csv')\n",
    "\n",
    "gam_fe = test.copy()\n",
    "gam_fe.columns = 'gam_' + gam_fe.columns\n",
    "gam_fe.to_csv('../data/gam_test_fe.csv')\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
